{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "import requests\n",
    "import pandas as pd\n",
    "from time import sleep \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splinter setup\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NASA Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NASA Announces Landing Site for Mars 2020 Rover',\n",
       " 'Opportunity Hunkers Down During Dust Storm',\n",
       " 'NASA Finds Ancient Organic Material, Mysterious Methane on Mars',\n",
       " 'NASA Invests in Visionary Technology',\n",
       " 'NASA is Ready to Study the Heart of Mars',\n",
       " 'NASA Briefing on First Mission to Study Mars Interior']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['After a five-year search, NASA has chosen Jezero Crater as the landing site for its upcoming Mars 2020 rover mission.',\n",
       " \"It's the beginning of the end for the planet-encircling dust storm on Mars. But it could still be weeks, or even months, before skies are clear enough for NASA's Opportunity rover to recharge its batteries and phone home.\",\n",
       " 'NASA’s Curiosity rover has found evidence on Mars with implications for NASA’s search for life.',\n",
       " 'NASA is investing in technology concepts, including several from JPL, that may one day be used for future space exploration missions.',\n",
       " 'NASA is about to go on a journey to study the center of Mars.',\n",
       " 'NASA’s next mission to Mars will be the topic of a media briefing Thursday, March 29, at JPL. The briefing will air live on NASA Television and the agency’s website.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nasa_url = \"https://mars.nasa.gov/news/\"\n",
    "nasa_response = requests.get(nasa_url, headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:63.0) Gecko/20100101 Firefox/63.0'})\n",
    "# creating bs object\n",
    "nasa_soup = bs(nasa_response.text,'html.parser')\n",
    "\n",
    "# NOTE: For whatever reason, the bs object generated here is not catching \n",
    "# information beyond Nov. 19th entry; even adding a User-Agent argument\n",
    "# (see https://stackoverflow.com/a/26741895) doesn't work.\n",
    "# See below for proof.\n",
    "\n",
    "all_news_titles_list = []\n",
    "all_news_titles = nasa_soup.find_all(\"div\", class_=\"content_title\")\n",
    "for title in all_news_titles:\n",
    "    all_news_titles_list.append(title.text.strip())\n",
    "all_news_titles_list\n",
    "\n",
    "all_news_p_list = []\n",
    "all_news_p = nasa_soup.find_all(\"div\", class_=\"rollover_description_inner\")\n",
    "for p in all_news_p:\n",
    "    all_news_p_list.append(p.text.strip())\n",
    "all_news_p_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NASA Announces Landing Site for Mars 2020 Rover'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'After a five-year search, NASA has chosen Jezero Crater as the landing site for its upcoming Mars 2020 rover mission.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_title = nasa_soup.find(\"div\", class_=\"content_title\").find(\"a\").text.strip()\n",
    "news_title\n",
    "\n",
    "news_p = nasa_soup.find(\"div\", class_=\"rollover_description_inner\").text.strip()\n",
    "news_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JPL Mars Space Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<splinter.driver.webdriver.WebDriverElement object at 0x000001E4EC30B5F8>, <splinter.driver.webdriver.WebDriverElement object at 0x000001E4EC30B5C0>, <splinter.driver.webdriver.WebDriverElement object at 0x000001E4EC30B710>, <splinter.driver.webdriver.WebDriverElement object at 0x000001E4EC30B898>, <splinter.driver.webdriver.WebDriverElement object at 0x000001E4EC30B3C8>, <splinter.driver.webdriver.WebDriverElement object at 0x000001E4EC30B8D0>, <splinter.driver.webdriver.WebDriverElement object at 0x000001E4EC30B748>]\n"
     ]
    }
   ],
   "source": [
    "jpl_url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "browser.visit(jpl_url)\n",
    "html = browser.html\n",
    "browser.click_link_by_partial_text('FULL IMAGE')\n",
    "sleep(5)\n",
    "browser.click_link_by_partial_text('more info')\n",
    "sleep(5)\n",
    "img_links = browser.find_link_by_partial_href('/spaceimages')\n",
    "print(img_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# note sure why it's returning these and not link text\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mars Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Listen to northwesterly winds blowing at 10-15 mph across the deck of the @NASAInSight landerhttps://www.youtube.com/watch?v=o3cxuIsEFRM\\xa0…',\n",
       " 'Well done! That 30 minutes of EDL dust settling was very effective. Shame #InSight can’t act as a supercharger for @marsrovers Oppy, she sure could use a boost right now.https://twitter.com/nasainsight/status/1068661716756516864\\xa0…',\n",
       " 'Sol 2242 (2018-11-26), high -2C/28F, low -70C/-93F, pressure at 8.48 hPa, daylight 06:29-18:45',\n",
       " 'Sol 2241 (2018-11-25), high -2C/28F, low -70C/-93F, pressure at 8.50 hPa, daylight 06:29-18:45',\n",
       " 'Sol 2240 (2018-11-24), high 0C/32F, low -70C/-93F, pressure at 8.49 hPa, daylight 06:28-18:44',\n",
       " 'Even through the dust covered lens cap of InSight’s first image, you can make out a blue cast to the sunlight caused by fine particulate in the Martian atmospherehttps://twitter.com/NASA/status/1067146825931661313\\xa0…',\n",
       " 'Even through the dust covered lens cap of InSight’s first image, you can make out a blue cast to the sunlight caused by fine particulate in the Martian atmospherehttps://twitter.com/NASA/status/1067146825931661313\\xa0…',\n",
       " 'The Martian robot meteorologist population increased by one today.\\n\\nWell done @NASAInSight team, looking forward to seeing that wind data.',\n",
       " 'The @NASAInSight mission lands today 11:54 am PT / 2:54 PM ET.  Temps, as usual, will be a bit chilly. Coverage starts on NASA TV at 11aPT/2pmET https://www.nasa.gov/nasalive\\xa0pic.twitter.com/kgQH8LGqzB',\n",
       " \"Nov 26, 2011  I launched\\nNov 26, 2018  InSight lands\\n                \\nI couldn't ask for a better sol mate, @NASAInSight! Looking forward to your #MarsLanding and all the discovery yet to come. http://mars.nasa.gov/InSight\\xa0pic.twitter.com/ixANAEqQMp\",\n",
       " 'Sol 2239 (2018-11-23), high -2C/28F, low -70C/-93F, pressure at 8.52 hPa, daylight 06:28-18:44',\n",
       " 'DYK friction from the thin Martian atmosphere will do 99% of the job of reducing @NASAInSight from 12,300 mph to just 5 mph when it lands tomorrow, read more at #WRAL https://www.wral.com/mission-to-mars-will-allow-for-robotic-exploration/18019494/\\xa0…pic.twitter.com/oLD28VKkCT',\n",
       " 'Sol 2238 (2018-11-22), high -2C/28F, low -69C/-92F, pressure at 8.53 hPa, daylight 06:27-18:43',\n",
       " 'Sol 2237 (2018-11-21), high -3C/26F, low -70C/-93F, pressure at 8.54 hPa, daylight 06:27-18:43',\n",
       " 'Sol 2236 (2018-11-20), high -3C/26F, low -71C/-95F, pressure at 8.57 hPa, daylight 06:26-18:42',\n",
       " 'Sol 2235 (2018-11-19), high 2C/35F, low -70C/-93F, pressure at 8.53 hPa, daylight 06:25-18:42',\n",
       " 'Sol 2234 (2018-11-18), high 2C/35F, low -70C/-93F, pressure at 8.57 hPa, daylight 06:25-18:41',\n",
       " 'Sol 2233 (2018-11-17), high -4C/24F, low -72C/-97F, pressure at 8.61 hPa, daylight 06:24-18:41',\n",
       " 'Sol 2232 (2018-11-16), high -3C/26F, low -73C/-99F, pressure at 8.58 hPa, daylight 06:24-18:40',\n",
       " 'Sol 2231 (2018-11-15), high -10C/14F, low -73C/-99F, pressure at 8.60 hPa, daylight 06:23-18:40']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "ValueError",
     "evalue": "'Sol ' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-56619bdfb0ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mweather_scraports\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# for scraport in weather_scraports:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mweather_scraports\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Sol '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;31m# or weather_scraports.index('high ') or weather_scraports.index('low ') or weather_scraports.index('pressure ') or weather_scraports.index('hPa') or weather_scraports.index('daylight')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'Sol ' is not in list"
     ]
    }
   ],
   "source": [
    "weather_url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "weather_response = requests.get(weather_url)\n",
    "weather_soup = bs(weather_response.text,'html.parser')\n",
    "\n",
    "weather_scraports = []\n",
    "weather_reports = weather_soup.find_all(\"div\", class_=\"js-tweet-text-container\")\n",
    "for report in weather_reports:\n",
    "    weather_scraports.append(report.find(\"p\", class_=\"tweet-text\").text.strip())\n",
    "weather_scraports\n",
    "\n",
    "# for scraport in weather_scraports:\n",
    "\n",
    "\n",
    "# trying to get first instance where there is the first Sol string (along with the other keywords below) \n",
    "# and then return that whole string, from the list; all in a nested if structure?\n",
    "weather_scraports.index('Sol ') \n",
    "\n",
    "# or weather_scraports.index('high ') or weather_scraports.index('low ') or weather_scraports.index('pressure ') or weather_scraports.index('hPa') or weather_scraports.index('daylight')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_url = \"https://space-facts.com/mars/\"\n",
    "fact_table_extract = pd.read_html(facts_url)\n",
    "fact_table = fact_table_extract[0]\n",
    "fact_table.columns = ['Fact', 'Value']\n",
    "fact_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"description\"><a class=\"itemLink product-item\" href=\"/search/map/Mars/Viking/cerberus_enhanced\"><h3>Cerberus Hemisphere Enhanced</h3></a><span class=\"subtitle\" style=\"float:left\">image/tiff 21 MB</span><span class=\"pubDate\" style=\"float:right\"></span><br/><p>Mosaic of the Cerberus hemisphere of Mars projected into point perspective, a view similar to that which one would see from a spacecraft. This mosaic is composed of 104 Viking Orbiter images acquired…</p></div>,\n",
       " <div class=\"description\"><a class=\"itemLink product-item\" href=\"/search/map/Mars/Viking/schiaparelli_enhanced\"><h3>Schiaparelli Hemisphere Enhanced</h3></a><span class=\"subtitle\" style=\"float:left\">image/tiff 35 MB</span><span class=\"pubDate\" style=\"float:right\"></span><br/><p>Mosaic of the Schiaparelli hemisphere of Mars projected into point perspective, a view similar to that which one would see from a spacecraft. The images were acquired in 1980 during early northern…</p></div>,\n",
       " <div class=\"description\"><a class=\"itemLink product-item\" href=\"/search/map/Mars/Viking/syrtis_major_enhanced\"><h3>Syrtis Major Hemisphere Enhanced</h3></a><span class=\"subtitle\" style=\"float:left\">image/tiff 25 MB</span><span class=\"pubDate\" style=\"float:right\"></span><br/><p>Mosaic of the Syrtis Major hemisphere of Mars projected into point perspective, a view similar to that which one would see from a spacecraft. This mosaic is composed of about 100 red and violet…</p></div>,\n",
       " <div class=\"description\"><a class=\"itemLink product-item\" href=\"/search/map/Mars/Viking/valles_marineris_enhanced\"><h3>Valles Marineris Hemisphere Enhanced</h3></a><span class=\"subtitle\" style=\"float:left\">image/tiff 27 MB</span><span class=\"pubDate\" style=\"float:right\"></span><br/><p>Mosaic of the Valles Marineris hemisphere of Mars projected into point perspective, a view similar to that which one would see from a spacecraft. The distance is 2500 kilometers from the surface of…</p></div>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'find_all'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-5e76cabeeaba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# grab the names from h3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mhemisphere_image_urls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhemisphere_image_divs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"h3\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhemisphere_image_urls\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mhi_res_hemis_urls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1883\u001b[0m         raise AttributeError(\n\u001b[1;32m-> 1884\u001b[1;33m             \u001b[1;34m\"ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1885\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: ResultSet object has no attribute 'find_all'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "hemispheres_url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "# browser.visit(hemispheres_url)\n",
    "# html = browser.html\n",
    "# hemispheres_soup = bs(html, 'html.parser')\n",
    "\n",
    "# make a list out of the four div class=\"item\", a.text, a.href\n",
    "\n",
    "\n",
    "hi_res_hemis_urls = []\n",
    "hemisphere_image_divs = hemispheres_soup.find_all(\"div\", class_=\"description\")\n",
    "hemisphere_image_divs\n",
    "\n",
    "# how to extract all a.text and a.href from here?\n",
    "\n",
    "# grab the names from h3 \n",
    "\n",
    "hemisphere_image_urls = hemisphere_image_divs.find_all(\"a\")\n",
    "for url in hemisphere_image_urls:\n",
    "    hi_res_hemis_urls.append(url.get(\"href\"))\n",
    "hi_res_hemis_urls\n",
    "\n",
    "\n",
    "# print(hemispheres_soup.prettify())\n",
    "\n",
    "\n",
    "\n",
    "hi_res_hemis_names =[]\n",
    "\n",
    "\n",
    "\n",
    "# need to make a list of dictionaries\n",
    "# use zip \n",
    "# https://stackoverflow.com/questions/14150797/converting-two-lists-to-a-list-of-dictionaries-in-python\n",
    "\n",
    "\n",
    "hi_res_hemis = [\n",
    "    # {\"title\": \" \", \"img_url\": \" \"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop\n",
    "# browser.back()\n",
    "\n",
    "# scrape craigslist exercise for reference \n",
    "\n",
    "# make soup first\n",
    "# store in a list the div items \n",
    "# for link in links_list that I'm gonna try to make\n",
    "\n",
    "# div class= items, there are 4 on the page\n",
    "# partial text click with \"enhanced\"\n",
    "# get link for link with \"original\"\n",
    "# with find link by text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
